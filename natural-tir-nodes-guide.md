# TIR Nodes: Complete Guide to AI Development Infrastructure

TIR (Tensor Infrastructure Resource) Nodes are fully collaborative environments that make AI development possible by combining the power of containers, Jupyter Labs, and AI/ML frameworks. These cloud-based development environments enable fine-tuning of Large Language Models, running Jupyter notebooks, downloading and testing datasets and models, and providing comprehensive command-line and SSH configuration options.

---

## Getting Started with TIR Nodes

TIR Nodes provide enterprise-grade AI development infrastructure designed for modern machine learning workflows. Whether you're fine-tuning large language models, conducting data science research, or building production AI applications, TIR Nodes offer the flexibility and power needed for advanced AI development.

### Key Capabilities

**Fine-tuning Large Language Models**: Optimize and customize LLMs for specific applications with dedicated GPU resources and optimized frameworks.

**Interactive Jupyter Development**: Access full-featured notebook environments pre-configured with popular data science libraries and AI frameworks.

**Dataset Management**: Efficiently handle large-scale datasets with high-performance storage options and automated data pipeline tools.

**Command-line Access**: Complete SSH and terminal access for advanced configurations, custom installations, and system-level optimizations.

**Collaborative Workflows**: Team-based development environments with shared resources, version control integration, and real-time collaboration features.

---

## Creating Your First TIR Node

The node creation process is designed to be intuitive while providing comprehensive configuration options for advanced users.

### Initiating Node Creation

![Create Node Button](https://docs.e2enetworks.com/assets/images/click_create_node-5cdfde38a5974bab42107967b1db8214.png)

The TIR dashboard provides a clean, organized interface where the "Create Node" button is prominently positioned for quick access. This centralized approach ensures users can immediately begin provisioning their development environments without navigating through complex menus.

Click the "Create Node" button to launch the configuration wizard, which will guide you through selecting the optimal setup for your specific AI development needs.

---

## Selecting the Right Environment

### Pre-built TIR Images

![TIR Pre-built Image Selection](https://docs.e2enetworks.com/assets/images/node_create_tirprebuilt-6fe32f7a774c2d3dadb7f5d167ca1392.png)

The image selection interface showcases E2E Networks' curated collection of AI-optimized environments. Each pre-built image is carefully configured with specific toolchains, frameworks, and libraries commonly used in AI development workflows.

**Jupyter Images** come pre-loaded with popular data science libraries including pandas, numpy, matplotlib, and scikit-learn, along with deep learning frameworks like TensorFlow and PyTorch. These environments are perfect for interactive development and experimentation.

**ComfyUI Images** provide visual, node-based interfaces for AI workflow design, particularly useful for creative AI applications and users who prefer graphical workflow management over code-based approaches.

**Framework-specific Images** are optimized for particular AI/ML frameworks, offering performance tuning and pre-installed dependencies that would otherwise require manual configuration.

> **ðŸ’¡ Quick Tip**: Choose images that closely match your intended workflow to minimize setup time and ensure optimal performance out of the box.

### Custom Base OS Configuration

![Base OS Configuration](https://docs.e2enetworks.com/assets/images/node_create_baseos-7822960dbeed2c236e77da807fe1c30e.png)

For users requiring maximum flexibility, the Base OS option provides a minimal foundation upon which you can build custom environments. The interface displays various Linux distributions with detailed version information and compatibility notes.

Ubuntu LTS versions are particularly recommended for AI/ML workloads due to their stability, extensive package ecosystem, and strong community support. The long-term support ensures your development environment remains stable and receives security updates throughout your project lifecycle.

When selecting a base OS, consider your team's existing standards, the specific requirements of your AI frameworks, and any organizational compliance requirements that might dictate particular operating system choices.

### Enterprise Container Integration

![Container Registry Configuration](https://docs.e2enetworks.com/assets/images/node_create_container_reg-7187dc5671d9cda2c7bbf059aa6e7fce.png)

Advanced teams often maintain custom container images in private registries or have specific versions of frameworks that aren't available in public repositories. The container registry integration allows seamless connection to Docker Hub, private registries, and custom repositories.

Authentication is handled securely through the interface, supporting both username/password and token-based authentication methods. This flexibility ensures compatibility with various organizational security policies and container management strategies.

**Best Practice**: Always use specific version tags (e.g., `tensorflow:2.13.0`) rather than generic tags like `latest` to ensure reproducible deployments and avoid unexpected changes when containers are rebuilt.

---

## Hardware Configuration

### Selecting Optimal Resources

![Node Resources Configuration](https://docs.e2enetworks.com/assets/images/node_create_noderesources-2d7398716d0e804ed64f0f5b77bde94f.png)

The resource configuration panel presents a comprehensive view of available hardware options with real-time pricing information. This transparency allows teams to make informed decisions balancing performance requirements with budget constraints.

**CPU Configurations** range from standard multi-core processors suitable for development and light training to high-performance CPUs with 16+ cores ideal for data preprocessing and inference workloads. Memory options scale from 16GB for basic development up to 256GB for handling large datasets and memory-intensive model training.

**GPU Options** include the latest NVIDIA hardware:
- **A100 GPUs** deliver exceptional performance for large model training and fine-tuning operations
- **V100 GPUs** provide balanced performance for most AI/ML workloads at a more accessible price point  
- **T4 GPUs** offer cost-effective acceleration perfect for inference and development environments

The interface displays detailed specifications for each option, including memory capacity, compute units, and estimated performance characteristics to help guide selection decisions.

### Advanced Resource Filtering

![CPU Filtering Interface](https://docs.e2enetworks.com/assets/images/node_create_CPU_filter-aa71d9fe294d2dbf7cd6a3c100c2f7e4.png)

The filtering system transforms resource selection from overwhelming to manageable by allowing precise specification of requirements. Users can set CPU architecture preferences, define memory ranges, specify GPU memory requirements, and apply budget constraints.

This granular control is particularly valuable for teams with specific technical requirements or budget limitations. The filtering immediately updates the available options, showing only configurations that meet all specified criteria.

**Optimization Strategy**: Start with filtering based on your minimum requirements, then compare the remaining options based on price-performance ratios to identify the most cost-effective solution for your needs.

---

## Storage Architecture

### Comprehensive Storage Options

![Storage Configuration](https://docs.e2enetworks.com/assets/images/node_create_node_storage-078d77740cb90960b457a6b3581d607c.png)

TIR Nodes offer sophisticated storage architecture designed to meet diverse AI development requirements. The interface clearly distinguishes between different storage types and their optimal use cases.

**Persistent Storage** provides up to 5TB of reliable, network-attached storage that persists across node restarts and updates. This is ideal for datasets, trained models, and code repositories that need to be permanently preserved.

**Local NVMe Storage** delivers ultra-high-speed local storage perfect for temporary operations like model checkpoints, cache data, and high-throughput data processing tasks. While this storage is faster, it's ephemeral and will be lost if the node is recreated.

The pricing model is transparent, showing costs for different storage tiers and helping teams optimize their storage strategy based on access patterns and performance requirements.

**Storage Strategy**: Use local NVMe for temporary, high-speed operations and persistent storage for permanent data. This hybrid approach maximizes both performance and cost-effectiveness.

---

## Automation and Scripting

### Startup Script Configuration

![Startup Script Configuration](https://docs.e2enetworks.com/assets/images/nodescript01-d505d96b46b19d431e6cf08608444f5f.png)

The script configuration interface empowers users to create fully automated environment setup through custom startup scripts. This feature transforms manual setup processes into repeatable, version-controlled automation.

Common automation scenarios include:

**Environment Preparation**
```bash
#!/bin/bash
# Update system packages
apt-get update && apt-get upgrade -y

# Install development tools
pip install --upgrade pip
pip install jupyter lab transformers datasets accelerate torch torchvision

# Configure Jupyter for remote access
jupyter lab --generate-config
echo "c.ServerApp.ip = '0.0.0.0'" >> ~/.jupyter/jupyter_lab_config.py
echo "c.ServerApp.allow_root = True" >> ~/.jupyter/jupyter_lab_config.py
```

**Data Pipeline Setup**
```bash
# Download and prepare datasets
mkdir -p /data/datasets
cd /data/datasets
wget https://example.com/dataset.tar.gz
tar -xzf dataset.tar.gz

# Set up model cache directory
export TRANSFORMERS_CACHE=/data/model_cache
mkdir -p $TRANSFORMERS_CACHE
```

The script editor includes syntax highlighting and basic validation to help prevent common configuration errors. Scripts execute during node initialization, ensuring your environment is immediately ready for productive work.

---

## Configuration Review and Deployment

### Final Configuration Summary

![Node Creation Summary](https://docs.e2enetworks.com/assets/images/node_create_summary_page-1797d59a189b44f565d84063ed62c368.png)

The comprehensive summary page serves as both a final review checkpoint and a documentation record of your node configuration. Every aspect of your setup is clearly displayed, from base image selection through hardware allocation to startup automation.

**Cost transparency** is a key feature, with detailed breakdown showing exactly how each configuration choice impacts your monthly or hourly charges. This information helps teams make informed trade-offs between performance and budget.

**Configuration validation** occurs automatically, checking for common issues like incompatible software combinations or resource constraints that might prevent successful node creation.

Take time to review each section carefullyâ€”this summary becomes your blueprint for future nodes and helps establish team standards for development environments.

---

## Node Status Management

### Understanding Node States

TIR Nodes operate through distinct status states that reflect their current operational condition and availability:

**Running**: Node is fully operational and accessible for development work. All resources are allocated and services are active.

**Stopped**: Node is gracefully shut down with all configurations preserved. Storage remains intact and the node can be quickly restarted.

**Pending**: Node is transitioning between states - either starting up, shutting down, or applying configuration changes.

**Waiting**: Node is queued for available resources in the selected region. This typically occurs during high-demand periods.

**Expired**: Node has reached its maximum runtime limit or encountered a critical error requiring manual intervention.

## Node Management Dashboard

### Comprehensive Operations Interface

![Node Management Interface](https://docs.e2enetworks.com/assets/images/Manage_Node_details-01f7278114b48534eee10f6a5a9a5afa.png)

The node management dashboard represents the command center for your AI development infrastructure. Unlike simple server management interfaces, this dashboard is specifically designed for the unique requirements of AI/ML workflows.

**Real-time Status Monitoring** provides immediate visibility into node health, resource utilization, and current operations. The status indicators go beyond simple "running/stopped" to include nuanced states like "initializing," "updating," and "saving image."

**Quick Action Buttons** enable rapid response to changing development needs:
- **Launch Notebook** provides one-click access to your Jupyter environment
- **SSH Access** opens secure terminal connections for command-line work
- **Resource Scaling** allows dynamic adjustment of CPU, GPU, and memory allocation
- **Image Management** facilitates saving custom environments and updating base images

The interface balances comprehensive functionality with intuitive operation, ensuring both novice and expert users can efficiently manage their development environments.

**Resource Optimization Insight**: The dashboard's utilization metrics help identify underused resources, enabling cost optimization through right-sizing recommendations.

### Node Actions and Operations

The management interface provides comprehensive control over node lifecycle and configuration:

**Launch Notebook**: Direct, one-click access to your Jupyter environment with automatic authentication and session management.

**SSH Access**: Secure shell access with pre-configured SSH keys for command-line development and system administration.

**Stop Node**: Graceful shutdown that preserves all data and configurations while stopping resource billing.

**Restart Node**: Quick restart maintaining all configurations - useful for applying updates or resolving temporary issues.

**Update Image**: Upgrade to newer base image versions while preserving custom configurations and data.

**Update Plan**: Modify resource allocations (CPU, GPU, memory) or change billing models (hourly to committed) without data loss.

**Save Image**: Create custom snapshots of your configured environment for reuse or sharing with team members.

**Delete Node**: Complete removal of node and associated resources - ensure critical data is backed up before deletion.

---

## Development Environment

### Jupyter Notebook Integration

![Notebook Overview Interface](https://docs.e2enetworks.com/assets/images/note_book_overview3-ea56bda8301e383531e7162eaf778941.png)

The Jupyter environment represents the heart of the TIR Node development experience. Rather than a standard Jupyter installation, this is a carefully optimized environment pre-configured for AI/ML workflows.

**Pre-installed Libraries** include the complete data science stackâ€”pandas for data manipulation, numpy for numerical computing, matplotlib and seaborn for visualization, and scikit-learn for traditional machine learning. Deep learning frameworks like TensorFlow and PyTorch come with GPU acceleration pre-configured.

**GPU Integration** is seamless, with CUDA libraries properly configured and accessible from notebook environments. This eliminates the common friction point of GPU setup that often challenges AI developers.

**Collaborative Features** enable real-time sharing and editing, making TIR Nodes ideal for team-based research and development projects. Version control integration helps maintain code quality and enables proper collaboration workflows.

The interface adapts to different development styles, supporting both exploratory data analysis and production-ready model development within the same environment.

### System Monitoring and Diagnostics

![Notebook Events](https://docs.e2enetworks.com/assets/images/notebook_event-29d16446a072d817fbebd5ab52221b6d.png)

Comprehensive logging and monitoring transform TIR Nodes from simple compute resources into intelligent development platforms. The event monitoring system captures detailed information about system operations, user activities, and performance metrics.

**Operational Intelligence** includes startup sequences, configuration changes, and system health events. This information proves invaluable for troubleshooting issues and optimizing performance.

**Security Auditing** tracks access patterns, authentication events, and permission changes, providing the audit trail required for enterprise security compliance.

**Performance Analytics** capture resource utilization patterns, helping teams understand their actual compute requirements and optimize future node configurations.

The event system operates transparently, providing valuable insights without impacting development workflow performance.

### Advanced Development Features

![Advanced Notebook Features](https://docs.e2enetworks.com/assets/images/Notebook8-d51412332b0237121acbd3f984fed64a.png)

The advanced notebook interface demonstrates TIR Nodes' sophisticated development capabilities that go far beyond basic Jupyter functionality. These features support professional AI development workflows requiring collaboration, debugging, and production deployment preparation.

**Multi-tab Development Environment** supports complex projects requiring simultaneous work across multiple notebooks, code files, and documentation. The interface maintains context across tabs, enabling efficient switching between different aspects of your project.

**Integrated Debugging Tools** provide step-through debugging capabilities with breakpoint management, variable inspection, and call stack analysis. These professional-grade debugging features are essential for complex AI model development and troubleshooting.

**Visualization and Analysis Tools** include interactive plotting capabilities with plotly and bokeh, automated data profiling tools, and model architecture visualization features. These tools accelerate the iterative process of model development and evaluation.

**Export and Deployment Features** facilitate the transition from development to production, with support for various output formats and integration with deployment pipelines.

---

## Workspace and Storage Management

### Default Workspace Configuration

Every TIR Node includes a **30GB free workspace** that provides immediate storage for development activities without additional cost. This workspace is automatically mounted and accessible from both Jupyter and SSH environments.

The free workspace is ideal for:
- Code repositories and development files
- Small datasets and sample data
- Model checkpoints and experimental results
- Temporary processing files and logs

### Advanced Storage Architecture

**Persistent Storage Integration**: Beyond the free workspace, TIR Nodes support up to 5TB of persistent storage that maintains data across node restarts, updates, and configuration changes.

**Local NVME Performance**: High-speed local storage provides exceptional performance for data-intensive operations like large model training, dataset preprocessing, and real-time inference serving.

**Network File System Access**: Integration with network storage systems enables sharing of large datasets across multiple nodes and collaboration with team members.

### SSH Configuration and Security

**SSH Key Management**: Secure access relies on SSH key pairs configured during node creation. Keys are managed through the E2E Networks interface and support both RSA and Ed25519 key types.

**Network Security**: All SSH connections use encrypted tunnels with configurable port access and IP filtering options for enhanced security in enterprise environments.

**Multi-user Access**: Team environments support multiple SSH keys, enabling secure collaborative access while maintaining individual user accountability and audit trails.

---

## Pricing and Billing Models

### Flexible Billing Options

**Hourly Billing**: Pay-per-use model ideal for development, experimentation, and variable workloads. Billing starts when nodes are running and stops immediately upon shutdown.

**Committed Plans**: Discounted rates for predictable, long-term usage. Committed plans offer significant cost savings for production workloads and continuous training operations.

### Cost Optimization Strategies

**Resource Right-sizing**: Monitor actual utilization through the dashboard metrics to identify opportunities for cost reduction through appropriate resource allocation.

**Automated Scheduling**: Use startup scripts and external automation to implement intelligent start/stop scheduling based on development patterns and business hours.

**Storage Tier Management**: Optimize costs by using the free 30GB workspace for active development and persistent storage for long-term data retention.

---

## Advanced Node Features

### Container-Native Development

TIR Nodes provide **container-native environments** that combine the flexibility of containerization with the performance of dedicated hardware. This architecture enables:

**Rapid Environment Switching**: Quick transitions between different development environments and framework versions without affecting underlying data.

**Reproducible Deployments**: Container-based environments ensure consistent behavior across development, testing, and production environments.

**Custom Image Creation**: Save and share customized environments as container images, enabling team standardization and rapid onboarding.

### Collaborative Development Features

**Shared Workspaces**: Multiple team members can access the same node environment, enabling real-time collaboration on AI projects.

**Version Control Integration**: Built-in Git support with automated synchronization capabilities for team-based development workflows.

**Resource Sharing**: Efficient sharing of expensive GPU resources across team members while maintaining individual development environments.

### Advanced Filtering and Search

**Multi-criteria Filtering**: Advanced search capabilities enable precise node selection based on status, resource utilization, cost parameters, and custom tags.

**Resource Optimization Views**: Specialized dashboard views highlight underutilized resources and provide optimization recommendations.

**Team Management**: Organization-level views provide managers with visibility into team resource usage and cost allocation.

---

## Advanced Configuration Areas

The following sections require additional screenshots from the original documentation. Each represents a crucial aspect of TIR Node functionality:

### **[PLACEHOLDER: Advanced Image Selection]**
*Multiple screenshots showing specialized pre-built images for different AI frameworks*

The expanded image gallery includes specialized environments for computer vision, natural language processing, reinforcement learning, and domain-specific applications. Each image represents hundreds of hours of optimization work, providing instantly usable environments for specific AI domains.

### **[PLACEHOLDER: Detailed Hardware Options]**  
*Screenshots of GPU selection interfaces, memory configuration panels, and CPU variants*

Hardware selection interfaces provide detailed specifications for each option, including benchmark performance data, power consumption characteristics, and optimal use case recommendations. This information enables data-driven hardware selection decisions.

### **[PLACEHOLDER: Network and Security Configuration]**
*Screenshots showing firewall settings, VPC configuration, and access control options*

Network configuration options include VPC integration, custom security group creation, and granular firewall rule management. These features enable TIR Nodes to integrate seamlessly with existing enterprise infrastructure while maintaining security best practices.

### **[PLACEHOLDER: User Management and Permissions]**
*Screenshots of team management interfaces and role-based access controls*

Multi-user environments require sophisticated permission management. The interface provides role-based access control, resource quota management, and collaborative workspace organization features essential for team-based AI development.

### **[PLACEHOLDER: Billing and Cost Analytics]**
*Screenshots of detailed pricing breakdowns, usage analytics, and cost optimization recommendations*

Cost management interfaces provide granular visibility into resource consumption patterns, predictive billing analytics, and automated cost optimization recommendations. These tools help teams maximize their AI development budget efficiency.

### **[PLACEHOLDER: Template and Automation Management]**
*Screenshots showing configuration templates, automated deployment options, and workflow integration*

Template systems enable standardization of development environments across teams and projects. Automation features integrate with CI/CD pipelines and infrastructure-as-code tools for enterprise-scale AI development operations.

### **[PLACEHOLDER: Performance Monitoring Dashboards]**
*Screenshots of detailed performance metrics, resource utilization graphs, and optimization recommendations*

Performance monitoring goes beyond basic resource utilization to include AI-specific metrics like training throughput, model inference performance, and data pipeline efficiency. These insights enable continuous optimization of development workflows.

### **[PLACEHOLDER: Integration and API Configuration]**
*Screenshots showing external service connections, webhook configurations, and API management interfaces*

Integration capabilities connect TIR Nodes with external data sources, model registries, deployment platforms, and monitoring systems. These connections enable TIR Nodes to function as part of comprehensive AI development and deployment ecosystems.

---

## Optimization Strategies

### Resource Management Excellence

Successful TIR Node utilization requires understanding the relationship between resource allocation, workload characteristics, and cost optimization. The most effective teams develop systematic approaches to resource management that balance performance requirements with budget constraints.

**Dynamic Resource Scaling** becomes crucial for variable workloads. Development work might require minimal resources, while training large models demands maximum GPU allocation. The ability to adjust resources dynamically enables cost-effective resource utilization.

**Storage Strategy Optimization** involves understanding data access patterns and matching storage types to usage requirements. Frequently accessed datasets benefit from high-speed local storage, while archival data can utilize more cost-effective persistent storage options.

**Collaborative Resource Sharing** maximizes team efficiency by enabling shared access to expensive resources like high-end GPUs while maintaining individual development environments for personal productivity.

### Security and Compliance Best Practice

Enterprise AI development requires robust security measures that protect intellectual property while enabling collaborative development workflows.

**Access Control Strategy** implements principle of least privilege while maintaining development agility. SSH key management, network access restrictions, and audit logging provide security without hindering productivity.

**Data Protection Measures** ensure sensitive datasets and proprietary models remain secure throughout the development lifecycle. Encryption at rest and in transit, secure data transfer protocols, and access audit trails provide comprehensive data protection.

**Compliance Integration** supports various regulatory requirements through detailed logging, access controls, and data handling procedures that meet industry-specific compliance standards.

### Development Workflow Optimization

**Environment Standardization** reduces onboarding time and eliminates environment-related issues by establishing team standards for node configurations, installed libraries, and development practices.

**Version Control Integration** maintains code quality and enables collaborative development through proper integration with Git repositories, automated backup procedures, and configuration versioning.

**Continuous Integration Support** enables automated testing, model validation, and deployment pipeline integration that supports professional AI development workflows.

---

## Troubleshooting and Support

### Common Challenge Resolution

**Node Creation Issues** typically stem from resource availability, quota limitations, or configuration incompatibilities. The most effective resolution approach involves systematic verification of account limits, resource availability in selected regions, and configuration validation.

**Performance Optimization** challenges often require analysis of resource utilization patterns, workload characteristics, and bottleneck identification. The monitoring tools provide detailed metrics for systematic performance analysis and optimization.

**Connectivity and Access Problems** usually involve network configuration, security settings, or authentication issues. Systematic verification of SSH keys, network connectivity, and security group configurations resolves most access-related challenges.

### Professional Support Resources

TIR Nodes provide comprehensive support resources designed for professional AI development teams:

**Technical Documentation** includes detailed guides, API references, and best practice recommendations developed through extensive real-world usage experience.

**Community Resources** connect users with peers facing similar challenges, providing collective problem-solving capabilities and knowledge sharing opportunities.

**Professional Support Services** offer expert assistance for complex technical challenges, architectural guidance, and custom integration requirements.

**Training and Certification Programs** enable teams to maximize their TIR Node utilization through structured learning paths and hands-on experience with advanced features.

---

## Conclusion

TIR Nodes represent a fundamental advancement in AI development infrastructure, providing the sophisticated capabilities required for modern machine learning workflows while maintaining the simplicity and accessibility that enables rapid innovation.

The platform's strength lies in its comprehensive approachâ€”combining powerful hardware options, optimized software environments, collaborative features, and professional management tools into a cohesive development platform specifically designed for AI applications.

**Strategic Value** emerges from TIR Nodes' ability to eliminate infrastructure complexity while providing the flexibility and performance required for cutting-edge AI development. Teams can focus on model development and innovation rather than system administration and configuration management.

**Operational Excellence** results from the platform's sophisticated monitoring, automation, and optimization capabilities that enable efficient resource utilization and cost management at scale.

**Collaborative Innovation** becomes possible through features designed specifically for team-based AI development, including shared resources, collaborative editing, and integrated version control.

Whether you're conducting research, developing production applications, or training large-scale models, TIR Nodes provide the robust, flexible foundation necessary for success in today's competitive AI landscape. The platform grows with your needs, supporting everything from individual research projects to enterprise-scale AI development operations.

The future of AI development requires infrastructure that matches the sophistication and ambition of modern machine learning applications. TIR Nodes deliver that infrastructure today, enabling teams to build the AI applications of tomorrow.